#!/usr/bin/env python3
"""Clean extracted text files with UUID-based safe filenames."""

from __future__ import annotations

import argparse
import hashlib
import json
import re
from pathlib import Path
from unicodedata import normalize


def clean_text(text: str) -> str:
    """Clean text by removing special characters and normalizing."""
    # Unicode normalize (NFC)
    text = normalize("NFC", text)
    
    # Remove page numbers (e.g., "1", "2", "3" at start of lines)
    text = re.sub(r'^\d+\s*$', '', text, flags=re.MULTILINE)
    
    # Remove excessive whitespace and normalize line breaks
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    text = re.sub(r'[ \t]+', ' ', text)
    
    # Remove special characters but keep Korean and English
    text = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,!?;:()\[\]{}"\'-]', '', text)
    
    return text.strip()


def generate_safe_filename(text: str, original_name: str) -> tuple[str, str]:
    """Generate UUID-based safe filename and metadata."""
    # Generate hash from text content for consistent naming
    text_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()[:12]
    safe_name = f"uuid-{text_hash}.txt"
    
    # Create metadata
    metadata = {
        "original_filename": original_name,
        "text_hash": text_hash,
        "text_length": len(text),
        "created_at": "",
        "tags": [],
        "origin": "ì‚¬ë‚´ ë¬¸ì„œ"
    }
    
    return safe_name, metadata


def process_file(file_path: Path, output_dir: Path) -> tuple[bool, str]:
    """Process a single file and return success status and message."""
    try:
        text = file_path.read_text(encoding="utf-8", errors="ignore")
        
        # ì‹¤íŒ¨í•œ ì¶”ì¶œ íŒŒì¼ ê±´ë„ˆë›°ê¸°
        if text.startswith("Extraction failed:") or text.startswith("Extraction skipped:"):
            return False, f"ê±´ë„ˆëœ€: ì¶”ì¶œ ì‹¤íŒ¨/ê±´ë„ˆëœ€ íŒŒì¼"
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°
        if not text.strip():
            return False, f"ê±´ë„ˆëœ€: ë¹ˆ í…ìŠ¤íŠ¸"
        
        cleaned = clean_text(text)
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°
        if not cleaned.strip():
            return False, f"ê±´ë„ˆëœ€: ì •ì œ í›„ ë¹ˆ í…ìŠ¤íŠ¸"
        
        # Generate safe filename and metadata
        safe_name, metadata = generate_safe_filename(cleaned, file_path.name)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save cleaned text
        out_path = output_dir / safe_name
        out_path.write_text(cleaned, encoding="utf-8")
        
        # Save metadata
        meta_path = output_dir / f"{safe_name}.meta.json"
        meta_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding="utf-8")
        
        return True, f"cleaned: {out_path} (ì›ë³¸: {file_path.name})"
        
    except Exception as e:
        return False, f"ì˜¤ë¥˜: {str(e)}"


def main() -> None:
    parser = argparse.ArgumentParser(description="Clean extracted text files with UUID naming")
    parser.add_argument("--input", default="data/extracted", help="Input directory")
    parser.add_argument("--output", default="data/cleaned", help="Output directory")
    args = parser.parse_args()

    input_dir = Path(args.input)
    output_dir = Path(args.output)

    if not input_dir.exists():
        print(f"Input directory not found: {input_dir}")
        return

    success_count = 0
    skipped_count = 0
    error_count = 0

    for file_path in input_dir.glob("*.txt"):
        success, message = process_file(file_path, output_dir)
        if success:
            print(f"âœ… {message}")
            success_count += 1
        else:
            print(f"â­ï¸  {file_path.name}: {message}")
            if "ì˜¤ë¥˜" in message:
                error_count += 1
            else:
                skipped_count += 1

    print(f"\nğŸ“Š ì •ì œ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ê±´ë„ˆëœ€ {skipped_count}ê°œ, ì˜¤ë¥˜ {error_count}ê°œ")


if __name__ == "__main__":
    main()
